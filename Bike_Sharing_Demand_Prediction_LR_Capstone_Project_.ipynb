{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.6"
    },
    "colab": {
      "name": " Bike_Sharing_Demand_Prediction_LR_Capstone_Project .ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/abhisekranaa/Bike-sharing-demand-prediction/blob/main/Bike_Sharing_Demand_Prediction_LR_Capstone_Project_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tOGC-qoyhJeX"
      },
      "source": [
        "# <b><u> Project Title : Seoul Bike Sharing Demand Prediction </u></b>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y06xIdG26kRF"
      },
      "source": [
        "## <b> Problem Description </b>\n",
        "\n",
        "### Currently Rental bikes are introduced in many urban cities for the enhancement of mobility comfort. It is important to make the rental bike available and accessible to the public at the right time as it lessens the waiting time. Eventually, providing the city with a stable supply of rental bikes becomes a major concern. The crucial part is the prediction of bike count required at each hour for the stable supply of rental bikes.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AlLxAtlziMbP"
      },
      "source": [
        "## <b> Data Description </b>\n",
        "\n",
        "### <b> The dataset contains weather information (Temperature, Humidity, Windspeed, Visibility, Dewpoint, Solar radiation, Snowfall, Rainfall), the number of bikes rented per hour and date information.</b>\n",
        "\n",
        "\n",
        "### <b>Attribute Information: </b>\n",
        "\n",
        "* ### Date : year-month-day\n",
        "* ### Rented Bike count - Count of bikes rented at each hour\n",
        "* ### Hour - Hour of he day\n",
        "* ### Temperature-Temperature in Celsius\n",
        "* ### Humidity - %\n",
        "* ### Windspeed - m/s\n",
        "* ### Visibility - 10m\n",
        "* ### Dew point temperature - Celsius\n",
        "* ### Solar radiation - MJ/m2\n",
        "* ### Rainfall - mm\n",
        "* ### Snowfall - cm\n",
        "* ### Seasons - Winter, Spring, Summer, Autumn\n",
        "* ### Holiday - Holiday/No holiday\n",
        "* ### Functional Day - NoFunc(Non Functional Hours), Fun(Functional hours)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "# **By Abhishek Rana**\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "CCQB1o7oLwM6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Loading Dataset and Importing Neccessary Modules**\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "F3AAgpqbFmfr"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dByMsuzT8Tnw"
      },
      "source": [
        "#let's import the modules\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import seaborn as sns\n",
        "\n",
        "from datetime import datetime\n",
        "import datetime as dt\n",
        "\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.preprocessing import MultiLabelBinarizer\n",
        "\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.linear_model import Lasso\n",
        "from sklearn.linear_model import Ridge\n",
        "from sklearn.linear_model import ElasticNet\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "\n",
        "from sklearn.model_selection import cross_validate\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import RepeatedStratifiedKFold\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import r2_score\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "from sklearn.metrics import log_loss\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Mounting and importing the datset from google drive\n"
      ],
      "metadata": {
        "id": "OciSqZM0F06p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#let's mount the google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "YTsWWIBLFzD6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0c4f0786-efde-44f5-dbad-7fbcf66dfe46"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#load the seol bike data set from drive\n",
        "bike_df=pd.read_csv('/content/drive/MyDrive/data/Seoul_Bike_Data.csv',encoding = 'latin')"
      ],
      "metadata": {
        "id": "jExYuaBTF3-i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Exploring and Understanding the Dataset**"
      ],
      "metadata": {
        "id": "yFH1OiOMGa_a"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##summary of data"
      ],
      "metadata": {
        "id": "__ywvF4mGgiC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Printing the Dataset\n",
        "pd.DataFrame(bike_df)"
      ],
      "metadata": {
        "id": "3dyF3OCIpHx7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Viewing the data of top 5 rows to take a glimps of the data\n",
        "bike_df.head()"
      ],
      "metadata": {
        "id": "ztF3MvWZGXqT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# View the bottom 5 rows to take a glimps of the data\n",
        "bike_df.tail()"
      ],
      "metadata": {
        "id": "2mZ8P2UWGjOD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Getting the shape of dataset with rows and columns\n",
        "print(bike_df.shape)"
      ],
      "metadata": {
        "id": "fgdoFA3tGnpj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Getting all the columns\n",
        "print(\"Features of the dataset:\")\n",
        "bike_df.columns"
      ],
      "metadata": {
        "id": "0DhDrLr2Gqgr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#check details about the data set\n",
        "bike_df.info()"
      ],
      "metadata": {
        "id": "a3pV66A2Gthx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#print the unique value\n",
        "bike_df.nunique()"
      ],
      "metadata": {
        "id": "JAhHbDHQGx2a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Looking for the description of the dataset to get insights of the data\n",
        "bike_df.describe().T"
      ],
      "metadata": {
        "id": "hU8a_cNCG2eK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* ***This Dataset contains 8760 lines and 14 columns.*** \n",
        "***In a day we have 24 hours and we have 365 days a year so 365 multiplied by 24 = 8760, which represents the number of line in the dataset.*** "
      ],
      "metadata": {
        "id": "LMIs95vgHFaz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Features description"
      ],
      "metadata": {
        "id": "6zFGJ4AZGtJh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Breakdown of Our Features:**\n",
        "\n",
        "**Date** : *The date of the day, during 365 days from 01/12/2017 to 30/11/2018, formating in DD/MM/YYYY, type : str*, we need to convert into datetime format.\n",
        "\n",
        "**Rented Bike Count** : *Number of rented bikes per hour which is dependent variable here and we need to predict that, type : int*\n",
        "\n",
        "**Hour**: *The hour of the day, starting from 0-23 it's in a digital time format, type : int, we need to convert it into category data type.*\n",
        "\n",
        "**Temperature(°C)**: *Temperature in Celsius, type : Float*\n",
        "\n",
        "**Humidity(%)**: *Humidity in the air in %, type : int*\n",
        "\n",
        "**Wind speed (m/s)** : *Speed of the wind in m/s, type : Float*\n",
        "\n",
        "**Visibility (10m)**: *Visibility in m, type : int*\n",
        "\n",
        "**Dew point temperature(°C)**: *Temperature at the beggining of the day, type : Float*\n",
        "\n",
        "**Solar Radiation (MJ/m2)**: *Sun contribution, type : Float*\n",
        "\n",
        "**Rainfall(mm)**: *Amount of raining in mm, type : Float*\n",
        "\n",
        "**Snowfall (cm)**: *Amount of snowing in cm, type : Float*\n",
        "\n",
        "**Seasons**: *Season of the year, type : str, there are only 4 season's in data *. \n",
        "\n",
        "**Holiday**: *If the day  is holiday period or not, type: str*\n",
        "\n",
        "**Functioning Day**: *If the day is a Functioning Day or not, type : str*\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "iEv9DlCCHQoS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Preprocessing the dataset**"
      ],
      "metadata": {
        "id": "X7XHr8X9HWGL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Missing values"
      ],
      "metadata": {
        "id": "RAh7WbpYHivL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The cause of missing values can be data corruption or failure to record data. The handling of missing data is very important during the preprocessing of the dataset as many machine learning algorithms do not support missing values."
      ],
      "metadata": {
        "id": "gxgmWTqMHioj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# counting missing values in each column.\n",
        "bike_df.isna().sum()\n",
        "bike_df.isnull().sum()"
      ],
      "metadata": {
        "id": "wZvsHPTpHQIK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Plotting the scatter plot\n",
        "missing = pd.DataFrame((bike_df.isnull().sum())*100/bike_df.shape[0]).reset_index()\n",
        "plt.figure(figsize=(16,5))\n",
        "ax = sns.scatterplot('index',0,data=missing)\n",
        "plt.xticks(rotation =45,fontsize =10,Weight='bold')\n",
        "plt.yticks(fontsize =10,Weight='bold')\n",
        "plt.title(\"Percentage of Missing values\",Weight='bold')\n",
        "plt.ylabel(\"PERCENTAGE\",Weight='bold')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Nw-pW3SDHpL8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* ***As we can see above there are no missing value present in the dataset***"
      ],
      "metadata": {
        "id": "4ZtCBJdNIOZp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Checking and removing Duplicate values.\n"
      ],
      "metadata": {
        "id": "f9xI-uKNIVWy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Checking Duplicate Values\n",
        "value=len(bike_df[bike_df.duplicated()])\n",
        "print(\"The number of duplicate values in the data set is = \",value)"
      ],
      "metadata": {
        "id": "TFT4ZUbcID16"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Renaming the columns for better understanding."
      ],
      "metadata": {
        "id": "9hwRBZQ0Iter"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Changing columns names.\n",
        "bike_df=bike_df.rename(columns={'Rented Bike Count':'Rented_Bike_Count',\n",
        "                                'Temperature(°C)':'Temperature',\n",
        "                                'Humidity(%)':'Humidity',\n",
        "                                'Wind speed (m/s)':'Wind_speed',\n",
        "                                'Visibility (10m)':'Visibility',\n",
        "                                'Dew point temperature(°C)':'Dew_point_temperature',\n",
        "                                'Solar Radiation (MJ/m2)':'Solar_Radiation',\n",
        "                                'Rainfall(mm)':'Rainfall',\n",
        "                                'Snowfall (cm)':'Snowfall',\n",
        "                                'Functioning Day':'Functioning_Day'})"
      ],
      "metadata": {
        "id": "c5eo2ai9IpGC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Splitting 'Date' column"
      ],
      "metadata": {
        "id": "dWjuHQF2JEkq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# splitting \"Date\" column into three other columns like \"year\",\"month\",\"day\".\n",
        "bike_df['Date'] = bike_df['Date'].apply(lambda x:dt.datetime.strptime(x,\"%d/%m/%Y\"))"
      ],
      "metadata": {
        "id": "0r7bX0x6I5Oj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#formating the Date column.\n",
        "bike_df['year'] = bike_df['Date'].dt.year\n",
        "bike_df['month'] = bike_df['Date'].dt.month\n",
        "bike_df['day'] = bike_df['Date'].dt.day_name()"
      ],
      "metadata": {
        "id": "HmKQgifdJOAS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#creating a new column of \"weekdays_weekend\" and drop the column \"Date\",\"day\",\"year\"\n",
        "bike_df['weekdays_weekend']=bike_df['day'].apply(lambda x : 1 if x=='Saturday' or x=='Sunday' else 0 )\n",
        "bike_df=bike_df.drop(columns=['Date','day','year'],axis=1)"
      ],
      "metadata": {
        "id": "O6194J9DJN4q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* ***So we convert the \"date\" column into 3 different column i.e \"year\",\"month\",\"day\".***\n",
        "* ***The \"year\" column in our data set is basically contains the details of data from 2017 december to 2018 november so if we consider this is as one year then we don't need \"year\" column so we drop it***.\n",
        "* ***The other column \"day\", it contains the details about the each day of the month, for our relevence we don't need each day of each month data but we need the data about, if a day is a weekday or a weekend so we convert it into this format and drop the \"day\" column***."
      ],
      "metadata": {
        "id": "sEjpI49SJWb6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Changing data type"
      ],
      "metadata": {
        "id": "-pscuVD_Jdn7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* ***As \"Hour\",\"month\",\"weekdays_weekend\" column data are integer data type but actually it should be category data type. so we need to change this data type if we not then, while doing the further anlysis and correletion with this, the values are not actually true so we can mislead by this.***"
      ],
      "metadata": {
        "id": "H-xP3owhJgPa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Change the int64 column into catagory column\n",
        "cols=['Hour','month','weekdays_weekend']\n",
        "for col in cols:\n",
        "  bike_df[col]=bike_df[col].astype('category')"
      ],
      "metadata": {
        "id": "JLthADHtJW5i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#let's check the result of data type\n",
        "bike_df.info()"
      ],
      "metadata": {
        "id": "QL59kGtdJ0ew"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Exploratory Data Analysis Of The Data Set**"
      ],
      "metadata": {
        "id": "ebEBREmfKRPc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "* ***Exploratory Data Analysis is a critical process of performing initial investigations on data so as to discover patterns,to spot anomalies,to test hypothesis and to check assumptions with the help of summary statistics and graphical representations.***"
      ],
      "metadata": {
        "id": "ooOZSPrwKWDT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Analysing categorical variables**\n",
        "* ***Our dependent variable is \"Rented Bike Count\" so we need to analysis this column with the other columns by using some visualisation plot.first we analyze the category data tyep then we proceed with the numerical data type***"
      ],
      "metadata": {
        "id": "9fzj8S6SKibS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Month"
      ],
      "metadata": {
        "id": "zw_7T6YhKos7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#anlysis of data by vizualisation by Month.\n",
        "fig,ax=plt.subplots(figsize=(20,8))\n",
        "sns.barplot(data=bike_df,x='month',y='Rented_Bike_Count',ax=ax,capsize=.25)\n",
        "ax.set(title='Count of Rented bikes acording to Month ')"
      ],
      "metadata": {
        "id": "Fzf9xxo-KR1C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* ***From the above bar plot we can clearly say that from  the month 5 to 10 the demand of the rented bike is high as compare to other months.these months are comes inside the summer season.***"
      ],
      "metadata": {
        "id": "EHFJ-W44LOhK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "####weekdays_weekend"
      ],
      "metadata": {
        "id": "3htC8CqpLSOc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#anlysis of data vizualisation for weekdays_weekend.\n",
        "fig,ax=plt.subplots(figsize=(10,8))\n",
        "sns.boxplot(data=bike_df,x='weekdays_weekend',y='Rented_Bike_Count',ax=ax)\n",
        "ax.set(title='Count of Rented bikes acording to weekdays and weekend ')"
      ],
      "metadata": {
        "id": "OaBWTlPjKtGS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* ***From the above box plot we can say that in the week days which represent in blue colur shows that the demand of the bike is higher because of the office/college timing.***\n",
        "***The orange colur represent the weekend days, and it show that the demand of rented bikes are very low specially in the morning hour but in evening hour  from 4 pm to 8 pm the demand slightly increases.***   "
      ],
      "metadata": {
        "id": "wxgRfKZSNDZs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Hour"
      ],
      "metadata": {
        "id": "KdG9URFtNNQy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#anlysis of data vizualisation for Hour column.\n",
        "fig,ax=plt.subplots(figsize=(20,8))\n",
        "sns.barplot(data=bike_df,x='Hour',y='Rented_Bike_Count',ax=ax,capsize=.2)\n",
        "ax.set(title='Count of Rented bikes acording to Hour ')"
      ],
      "metadata": {
        "id": "64UgUgr7M0GL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* ***In the above plot which shows the use of rented bike according the hours and the data are from all over the year.***\n",
        "\n",
        "* ***generally people use rented bikes during their working hour from 7am to 9am and 5pm to 7pm.***"
      ],
      "metadata": {
        "id": "-5Yj6EPWNkYk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Functioning Day\n"
      ],
      "metadata": {
        "id": "ya7DvLQhNpNK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#anlysis of data by vizualisation\n",
        "fig,ax=plt.subplots(figsize=(10,8))\n",
        "sns.barplot(data=bike_df,x='Rented_Bike_Count',y='Functioning_Day',ax=ax,capsize=.2)\n",
        "ax.set(title='Count of Rented bikes acording to Functioning Day ')"
      ],
      "metadata": {
        "id": "UjxJZRozNZSq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* ***From the above bar plot and point plot we conclude that, the use of rented bike in functioning days are quite good but in no functioning day People generally do not use reneted bikes.*** "
      ],
      "metadata": {
        "id": "z4TDbHFTOBmi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Seasons"
      ],
      "metadata": {
        "id": "peZ0d0OHOI7a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#anlysis of data by vizualisation\n",
        "fig,ax=plt.subplots(figsize=(15,8))\n",
        "sns.barplot(data=bike_df,x='Rented_Bike_Count',y='Seasons',ax=ax,capsize=.2)\n",
        "ax.set(title='Count of Rented bikes acording to Seasons ')"
      ],
      "metadata": {
        "id": "T-trgfJQNtm6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* ***In the above bar plot shows the use of rented bike in in four different seasons, and it clearly shows that,***\n",
        "* ***In summer season the use of rented bike is high and peak time is 7am-9am and 7pm-5pm.***\n",
        "* ***In winter season the use of rented bike is very low because of snowfall.***"
      ],
      "metadata": {
        "id": "KhlmWXdmOTjr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Holiday"
      ],
      "metadata": {
        "id": "_S_XB86cOe4T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#anlysis of data by vizualisation\n",
        "fig,ax=plt.subplots(figsize=(15,8))\n",
        "sns.barplot(data=bike_df,x='Holiday',y='Rented_Bike_Count',ax=ax,capsize=.2)\n",
        "ax.set(title='Count of Rented bikes acording to Holiday ')"
      ],
      "metadata": {
        "id": "Cv2lI2r8OPEr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* ***From the above bar plot we conlude that the use of rented bike count is higher in No Holiday as compare to Holiday.***"
      ],
      "metadata": {
        "id": "KXiG_Ns9Oxni"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Analysis on Numerical variables/Features**\n",
        "* Numerical data is always collected in Integer/Number form."
      ],
      "metadata": {
        "id": "JOla50cRO28S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#assign the numerical coulmns to variables.\n",
        "numerical_columns=list(bike_df.select_dtypes(['int64','float64']).columns)\n",
        "numerical_features=pd.Index(numerical_columns)\n",
        "numerical_features"
      ],
      "metadata": {
        "id": "7jWZwLdkOj5E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Visualization by using Boxplot to Identify outliers."
      ],
      "metadata": {
        "id": "wlYLMxXMiOdk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#showing boxplot to analyze the outliers of all numerical features\n",
        "for col in numerical_features:\n",
        "  plt.figure(figsize=(10,6))\n",
        "  sns.boxplot(x=bike_df[col])\n",
        "  plt.xlabel(col)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "RbyVrauLiAf9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Treating the Outliers"
      ],
      "metadata": {
        "id": "ifxan93uifpc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Capping the columns with most number of outliers\n",
        "\n",
        "bike_df.loc[bike_df['Rainfall']>=2,'Rainfall']= 2\n",
        "bike_df.loc[bike_df['Solar_Radiation']>=2,'Solar_Radiation']= 2\n",
        "bike_df.loc[bike_df['Snowfall']>=1.5,'Snowfall']= 1.5\n",
        "bike_df.loc[bike_df['Wind_speed']>=4,'Wind_speed']= 4"
      ],
      "metadata": {
        "id": "CyD76g5c3xOe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Again checking the outliers after capping/Trimming"
      ],
      "metadata": {
        "id": "G7g0WNKziziO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#printing boxplot to analyze the outliers again of all numerical features\n",
        "for col in numerical_features:\n",
        "  plt.figure(figsize=(10,6))\n",
        "  sns.boxplot(x=bike_df[col])\n",
        "  plt.xlabel(col)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "XGEFvm5kPC4C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### We have capped/Trimmed the outliers as removing them results in loss of data which is not subsequent in real world. Trimming the outliers helps us not to loose data and increase our model accuracy by even more."
      ],
      "metadata": {
        "id": "Z8UgmCIXi_MY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Numerical vs.Rented_Bike_Count"
      ],
      "metadata": {
        "id": "MQ_CFAK6PXDk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#print the plot to analyze the relationship between \"Rented_Bike_Count\" and \"Temperature\" \n",
        "bike_df.groupby('Temperature').mean()['Rented_Bike_Count'].plot()"
      ],
      "metadata": {
        "id": "O5X9QyeTPBeD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* ***From the above plot we see that people like to ride bikes when it is pretty hot around 25°C in average***"
      ],
      "metadata": {
        "id": "izhfToIjPrxy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Checking relationship between dependent and indepedent variables."
      ],
      "metadata": {
        "id": "vW1Ja-SEjk9F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#analysing the relationship using graph between \"Rented_Bike_Count\" and \"Dew_point_temperature\" \n",
        "bike_df.groupby('Dew_point_temperature').mean()['Rented_Bike_Count'].plot()"
      ],
      "metadata": {
        "id": "PnyboiVMPsJ7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* ***From the above plot of \"Dew_point_temperature' is almost same as the 'temperature' there is some similarity present we can check it in our next step.***"
      ],
      "metadata": {
        "id": "oL216HtHPx_y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#print the plot to analyze the relationship between \"Rented_Bike_Count\" and \"Solar_Radiation\" \n",
        "bike_df.groupby('Solar_Radiation').mean()['Rented_Bike_Count'].plot()"
      ],
      "metadata": {
        "id": "KG3t17LMPvEM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* ***from the above plot we see that, the amount of rented bikes is huge, when there is solar radiation, the counter of rents is around 1000***"
      ],
      "metadata": {
        "id": "Uji6bwucP-sK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#plot to analyze the relationship between \"Rented_Bike_Count\" and \"Snowfall\" \n",
        "bike_df.groupby('Snowfall').mean()['Rented_Bike_Count'].plot()"
      ],
      "metadata": {
        "id": "uBL-6w9hP_Pa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* ***We can see from the plot that, on the y-axis, the amount of rented bike is very low When we have more than 4 cm of snow, the bike rents is very less***"
      ],
      "metadata": {
        "id": "UvdxiarPQGT7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#plot to analyze the relationship between \"Rented_Bike_Count\" and \"Rainfall\" \n",
        "bike_df.groupby('Rainfall').mean()['Rented_Bike_Count'].plot()"
      ],
      "metadata": {
        "id": "zlEEfAhlQIKT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* ***We can see from the above plot that even in rainfall the demands of rental bikes are not decreasing, here for example even if we have 20 mm of rain there is a big peak of rented bikes.***"
      ],
      "metadata": {
        "id": "8M4Z1LCPQNTq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# plot to analyze the relationship between \"Rented_Bike_Count\" and \"Wind_speed\" \n",
        "bike_df.groupby('Wind_speed').mean()['Rented_Bike_Count'].plot()"
      ],
      "metadata": {
        "id": "xfQIFZ8iQKZz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* ***We can see from the above plot that the demand of rental bike is uniformly distributed in wind_speed it means most of the people uses rental bike in Wind condition.***"
      ],
      "metadata": {
        "id": "QCID-TDgQdZi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Transforming Rented_Bike_Count column data**"
      ],
      "metadata": {
        "id": "L1h1nbUbQ1zD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* ***The data Transformation (also referred to as data pre-processing) is a basic element of data mining. It means transforming the data, namely converting the source data in to another format that allows processing data effectively. The main purpose of data normalization is to minimize or even exclude duplicated data***"
      ],
      "metadata": {
        "id": "pbCCFlO-Q7XG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Distribution plot of Rented Bike Count\n",
        "plt.figure(figsize=(10,6))\n",
        "plt.xlabel('Rented_Bike_Count')\n",
        "plt.ylabel('Density')\n",
        "ax=sns.distplot(bike_df['Rented_Bike_Count'],hist=True ,color=\"y\")\n",
        "ax.axvline(bike_df['Rented_Bike_Count'].mean(), color='magenta', linestyle='dashed', linewidth=2)\n",
        "ax.axvline(bike_df['Rented_Bike_Count'].median(), color='black', linestyle='dashed', linewidth=2)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "0sBdmKSKQdv7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* ***The above graph shows that Rented Bike Count has moderate right skewness. Since the assumption of linear regression is that 'the distribution of dependent variable has to be normal', so we should perform some operation to normalize it.***"
      ],
      "metadata": {
        "id": "MSXaoNWsRE8a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Boxplot of Rented Bike Count to check outliers\n",
        "plt.figure(figsize=(10,6))\n",
        "plt.ylabel('Rented_Bike_Count')\n",
        "sns.boxplot(x=bike_df['Rented_Bike_Count'])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "xybT298xRAaz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Applying square root to Rented Bike Count to improve skewness\n",
        "plt.figure(figsize=(10,8))\n",
        "plt.xlabel('Rented Bike Count')\n",
        "plt.ylabel('Density')\n",
        "\n",
        "ax=sns.distplot(np.sqrt(bike_df['Rented_Bike_Count']), color=\"y\")\n",
        "ax.axvline(np.sqrt(bike_df['Rented_Bike_Count']).mean(), color='magenta', linestyle='dashed', linewidth=2)\n",
        "ax.axvline(np.sqrt(bike_df['Rented_Bike_Count']).median(), color='black', linestyle='dashed', linewidth=2)\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "NF1ub50mRKNC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* ***Since we have generic rule of applying Square root for the skewed variable in order to make it normal .After applying Square root to the skewed Rented Bike Count, here we get almost normal distribution.***"
      ],
      "metadata": {
        "id": "2DOEHuzIRxcT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#After applying sqrt on Rented Bike Count check wheater we still have outliers \n",
        "plt.figure(figsize=(10,6))\n",
        "\n",
        "plt.ylabel('Rented_Bike_Count')\n",
        "sns.boxplot(x=np.sqrt(bike_df['Rented_Bike_Count']))\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "N97gSi4dRoDs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* ***After applying Square root to the Rented Bike Count column, we find that there is no outliers present.***\n"
      ],
      "metadata": {
        "id": "JdLAaSaiR9CK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Checking of Correlation between variables**"
      ],
      "metadata": {
        "id": "hHUNTawiR7V7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Checking in OLS Model"
      ],
      "metadata": {
        "id": "lFXO4pmej6Xm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Ordinary least squares (OLS) regression is a statistical method of analysis that estimates the relationship between one or more independent variables and a dependent variable**"
      ],
      "metadata": {
        "id": "0g0XttyRj-et"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#import the module\n",
        "#assign the 'x','y' value\n",
        "import statsmodels.api as sm\n",
        "X = bike_df[[ 'Temperature','Humidity',\n",
        "       'Wind_speed', 'Visibility','Dew_point_temperature',\n",
        "       'Solar_Radiation', 'Rainfall', 'Snowfall']]\n",
        "Y = bike_df['Rented_Bike_Count']\n",
        "bike_df.head()"
      ],
      "metadata": {
        "id": "rk_v2gP8kAzd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#add a constant column\n",
        "X = sm.add_constant(X)\n",
        "X"
      ],
      "metadata": {
        "id": "TvMtzibVkDP1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## fit a OLS model \n",
        "\n",
        "model= sm.OLS(Y, X).fit()\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "d1LBxQm6kFFV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#checking correlation\n",
        "X.corr()"
      ],
      "metadata": {
        "id": "Rrj_4aaEkJ2_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* ***From the OLS model we find that the 'Temperature' and  'Dew_point_temperature' are highly correlated so we need to drop one of them.***\n",
        "* ***for droping, we check the (P>|t|) value from above table and we can see that the 'Dew_point_temperature' value is higher so we need to drop Dew_point_temperature column***\n",
        "* ***For clarity, we use visualisation i.e heatmap in next step***"
      ],
      "metadata": {
        "id": "JnG5TtKnkN-9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**Heatmap Correlation**"
      ],
      "metadata": {
        "id": "z0hDZvVPkSDV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " we check correletion betweeen variables using Correlation heatmap, it is graphical representation of correlation matrix representing correlation between different variables."
      ],
      "metadata": {
        "id": "GqmxFTAEkuY3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating the heatmap\n",
        "plt.figure(figsize=(15,10))\n",
        "sns.heatmap(bike_df.corr(),cmap='PiYG',annot=True)"
      ],
      "metadata": {
        "id": "g8Y25htQR1ab"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "***We can observe on the heatmap that on the target variable line the most positively correlated variables to the rent are :***\n",
        "\n",
        "* the temperature\n",
        "* the dew point temperature\n",
        "* the solar radiation\n",
        "\n",
        "***And most negatively correlated variables are:***\n",
        "* Humidity\n",
        "* Rainfall"
      ],
      "metadata": {
        "id": "RL8nvLgySsAT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#drop the column.\n",
        "bike_df=bike_df.drop(['Dew_point_temperature'],axis=1)\n"
      ],
      "metadata": {
        "id": "gUIxocPCSVn8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#According to OLS these columns are not nessessary.\n",
        "bike_df=bike_df.drop(['Snowfall'],axis=1)\n",
        "bike_df=bike_df.drop(['Visibility'],axis=1)\n"
      ],
      "metadata": {
        "id": "ePz9uNlhj0q7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* ***From the above correlation heatmap, We see that there is a positive \n",
        "correlation between columns 'Temperature' and 'Dew point temperature' i.e 0.91 so even if we drop this column then it don't affects the outcome of our analysis. And they have the same variations. so we can drop the column 'Dew point temperature(°C)'.***"
      ],
      "metadata": {
        "id": "qvTPs1hbTAI7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create the dummy variables "
      ],
      "metadata": {
        "id": "7oBumLRcTb1j"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**A dataset may contain different type of values, sometimes they consist categorical features. So, in-order to use those categorical value for programming efficiently we create dummy variables.**"
      ],
      "metadata": {
        "id": "j--XWJDfTgVz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Assign all catagoriacla features to a variable\n",
        "categorical_features=list(bike_df.select_dtypes(['object','category']).columns)\n",
        "categorical_features=pd.Index(categorical_features)\n",
        "categorical_features"
      ],
      "metadata": {
        "id": "HpDJqUb4TAkc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###one hot encoding\n",
        "**A one hot encoding allows the representation of categorical data to be more expressive.**"
      ],
      "metadata": {
        "id": "TTP6AoUjTkz2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#creating a copy\n",
        "bike_df_copy = bike_df\n",
        "\n",
        "def one_hot_encoding(data, column):\n",
        "    data = pd.concat([data, pd.get_dummies(data[column], prefix=column, drop_first=True)], axis=1)\n",
        "    data = data.drop([column], axis=1)\n",
        "    return data\n",
        "\n",
        "for col in categorical_features:\n",
        "    bike_df_copy = one_hot_encoding(bike_df_copy, col)\n",
        "bike_df_copy.head() "
      ],
      "metadata": {
        "id": "Ez3tgtWETiv8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Multicollinearity\n",
        "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
        "def calc_vif(X):\n",
        "\n",
        "    # Calculating VIF\n",
        "    vif = pd.DataFrame()\n",
        "    vif[\"variables\"] = X.columns\n",
        "    vif[\"VIF\"] = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]\n",
        "\n",
        "    return(vif)"
      ],
      "metadata": {
        "id": "WbTB7x-WT1Ds"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Calcualting VIF\n",
        "calc_vif(bike_df_copy[[i for i in bike_df_copy.describe().columns if i not in ['Rented_Bike_Count',]]])"
      ],
      "metadata": {
        "id": "zCyozfMqiTHS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Assign the value in X and Y\n",
        "X = bike_df_copy.drop(columns=['Rented_Bike_Count'], axis=1)\n",
        "y = np.sqrt(bike_df_copy['Rented_Bike_Count'])"
      ],
      "metadata": {
        "id": "JIlfBGHPqlG0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Creat test and train data\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.2, random_state=1)\n",
        "print(X_train.shape)\n",
        "print(X_test.shape)"
      ],
      "metadata": {
        "id": "NwyA1prxkdAh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#checking columns\n",
        "bike_df_copy.describe().columns"
      ],
      "metadata": {
        "id": "HRZOQS7Jkdey"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#import the packages for linear regression\n",
        "from sklearn.linear_model import LinearRegression\n",
        "reg= LinearRegression().fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "Oez-BBwRkiXy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#check the regression score\n",
        "reg.score(X_train, y_train)"
      ],
      "metadata": {
        "id": "v6nXbzE0klcb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#check the coefficeint\n",
        "reg.coef_"
      ],
      "metadata": {
        "id": "ZHAHQY2vlZRV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#get the X_train and X-test value\n",
        "y_pred_train=reg.predict(X_train)\n",
        "y_pred_test=reg.predict(X_test)"
      ],
      "metadata": {
        "id": "WYXjgCGzlZJu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Evaluation Matrix"
      ],
      "metadata": {
        "id": "vGVg8JxyloOW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#import the packages\n",
        "from sklearn.metrics import mean_squared_error\n",
        "#calculate MSE\n",
        "MSE_lr= mean_squared_error((y_train), (y_pred_train))\n",
        "print(\"MSE :\",MSE_lr)\n",
        "\n",
        "#calculate RMSE\n",
        "RMSE_lr=np.sqrt(MSE_lr)\n",
        "print(\"RMSE :\",RMSE_lr)\n",
        "\n",
        "\n",
        "#calculate MAE\n",
        "MAE_lr= mean_absolute_error(y_train, y_pred_train)\n",
        "print(\"MAE :\",MAE_lr)\n",
        "\n",
        "\n",
        "\n",
        "#import the packages\n",
        "from sklearn.metrics import r2_score\n",
        "#calculate r2 and adjusted r2\n",
        "r2_lr= r2_score(y_train, y_pred_train)\n",
        "print(\"R2 :\",r2_lr)\n",
        "Adjusted_R2_lr = (1-(1-r2_score(y_train, y_pred_train))*((X_test.shape[0]-1)/(X_test.shape[0]-X_test.shape[1]-1)) )\n",
        "print(\"Adjusted R2 :\",1-(1-r2_score(y_train, y_pred_train))*((X_test.shape[0]-1)/(X_test.shape[0]-X_test.shape[1]-1)) )"
      ],
      "metadata": {
        "id": "CmS-yAfemUPx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Looks like our r2 score value is 0.80 that means our model is  able to capture most of the data variance.**"
      ],
      "metadata": {
        "id": "MNgx44rIluf1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Checking Heteroscadacity after running Linear regression analysis over a range of measured values."
      ],
      "metadata": {
        "id": "ySxgfQDJic73"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### Heteroscadacity\n",
        "plt.scatter((y_pred_test),(y_test)-(y_pred_test),color='red')"
      ],
      "metadata": {
        "id": "p7wbjKC9lzY8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Plot the figure\n",
        "plt.figure(figsize=(15,10))\n",
        "plt.plot(y_pred_test)\n",
        "plt.plot(np.array(y_test))\n",
        "plt.legend([\"Predicted\",\"Actual\"])\n",
        "plt.xlabel('No of Test Data')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "9-PTIuJ5mE2m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# storing the Train set metrics value in a dataframe for later comparison\n",
        "dict1={'Model':'Linear regression ',\n",
        "       'MAE':round((MAE_lr),3),\n",
        "       'MSE':round((MSE_lr),3),\n",
        "       'RMSE':round((RMSE_lr),3),\n",
        "       'R2_score':round((r2_lr),3),\n",
        "       'Adjusted R2':round((Adjusted_R2_lr ),2)\n",
        "       }\n",
        "training_df=pd.DataFrame(dict1,index=[1])"
      ],
      "metadata": {
        "id": "Twfuyy5gn4MH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# storing the test set metrics value in a dataframe for later comparison\n",
        "dict2={'Model':'Linear regression ',\n",
        "       'MAE':round((MAE_lr),3),\n",
        "       'MSE':round((MSE_lr),3),\n",
        "       'RMSE':round((RMSE_lr),3),\n",
        "       'R2_score':round((r2_lr),3),\n",
        "       'Adjusted R2':round((Adjusted_R2_lr ),2)\n",
        "       }\n",
        "test_df=pd.DataFrame(dict2,index=[1])"
      ],
      "metadata": {
        "id": "wnSmvDqHoUkH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**LASSO REGRESSION** "
      ],
      "metadata": {
        "id": "jILxmbR5mKrm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create an instance of Lasso Regression implementation\n",
        "from sklearn.linear_model import Lasso\n",
        "lasso = Lasso(alpha=1.0, max_iter=3000)\n",
        "# Fit the Lasso model\n",
        "lasso.fit(X_train, y_train)\n",
        "# Create the model score\n",
        "print(lasso.score(X_test, y_test), lasso.score(X_train, y_train))"
      ],
      "metadata": {
        "id": "VUPVtnhXmNCH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#get the X_train and X-test value\n",
        "y_pred_train_lasso=lasso.predict(X_train)\n",
        "y_pred_test_lasso=lasso.predict(X_test)"
      ],
      "metadata": {
        "id": "GW6dqiApmP4X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import mean_squared_error\n",
        "#calculate MSE\n",
        "MSE_l= mean_squared_error((y_train), (y_pred_train_lasso))\n",
        "print(\"MSE :\",MSE_l)\n",
        "\n",
        "#calculate RMSE\n",
        "RMSE_l=np.sqrt(MSE_l)\n",
        "print(\"RMSE :\",RMSE_l)\n",
        "\n",
        "\n",
        "#calculate MAE\n",
        "MAE_l= mean_absolute_error(y_train, y_pred_train_lasso)\n",
        "print(\"MAE :\",MAE_l)\n",
        "\n",
        "\n",
        "from sklearn.metrics import r2_score\n",
        "#calculate r2 and adjusted r2\n",
        "r2_l= r2_score(y_train, y_pred_train_lasso)\n",
        "print(\"R2 :\",r2_l)\n",
        "Adjusted_R2_l = (1-(1-r2_score(y_train, y_pred_train_lasso))*((X_test.shape[0]-1)/(X_test.shape[0]-X_test.shape[1]-1)) )\n",
        "print(\"Adjusted R2 :\",1-(1-r2_score(y_train, y_pred_train_lasso))*((X_test.shape[0]-1)/(X_test.shape[0]-X_test.shape[1]-1)) )"
      ],
      "metadata": {
        "id": "qBqT44PomSlm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Plot the figure\n",
        "plt.figure(figsize=(15,10))\n",
        "plt.plot(np.array(y_pred_test_lasso))\n",
        "plt.plot(np.array((y_test)))\n",
        "plt.legend([\"Predicted\",\"Actual\"])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "gUGuHPEzmlyG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Checking Heteroscadacity after running Lasso regression."
      ],
      "metadata": {
        "id": "XejC_NvJjGaQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### Heteroscadacity\n",
        "plt.scatter((y_pred_test_lasso),(y_test-y_pred_test_lasso),color='green')"
      ],
      "metadata": {
        "id": "CyHRQWDLmoFn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# storing the test set metrics value in a dataframe for later comparison\n",
        "dict1={'Model':'Lasso regression ',\n",
        "       'MAE':round((MAE_l),3),\n",
        "       'MSE':round((MSE_l),3),\n",
        "       'RMSE':round((RMSE_l),3),\n",
        "       'R2_score':round((r2_l),3),\n",
        "       'Adjusted R2':round((Adjusted_R2_l ),2)\n",
        "       }\n",
        "training_df=training_df.append(dict1,ignore_index=True)"
      ],
      "metadata": {
        "id": "Jzl0a_NVoinf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# storing the test set metrics value in a dataframe for later comparison\n",
        "dict2={'Model':'Lasso regression ',\n",
        "       'MAE':round((MAE_l),3),\n",
        "       'MSE':round((MSE_l),3),\n",
        "       'RMSE':round((RMSE_l),3),\n",
        "       'R2_score':round((r2_l),3),\n",
        "       'Adjusted R2':round((Adjusted_R2_l ),2),\n",
        "       }\n",
        "test_df=test_df.append(dict2,ignore_index=True)"
      ],
      "metadata": {
        "id": "UKB4gxk1omdA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **RIDGE REGRESSION**"
      ],
      "metadata": {
        "id": "FjQP_jdGmqbu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#import the packages\n",
        "from sklearn.linear_model import Ridge\n",
        "\n",
        "ridge= Ridge(alpha=0.1)"
      ],
      "metadata": {
        "id": "zsgx9bTfmq03"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#FIT THE MODEL\n",
        "ridge.fit(X_train,y_train)"
      ],
      "metadata": {
        "id": "MJHMeQSamuQm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#check the score\n",
        "ridge.score(X_train, y_train)"
      ],
      "metadata": {
        "id": "IrxegUU1mv5a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#get the X_train and X-test value\n",
        "y_pred_train_ridge=ridge.predict(X_train)\n",
        "y_pred_test_ridge=ridge.predict(X_test)"
      ],
      "metadata": {
        "id": "rj42yTfZmyL2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#import the packages\n",
        "from sklearn.metrics import mean_squared_error\n",
        "#calculate MSE\n",
        "MSE_r= mean_squared_error((y_train), (y_pred_train_ridge))\n",
        "print(\"MSE :\",MSE_r)\n",
        "\n",
        "#calculate RMSE\n",
        "RMSE_r=np.sqrt(MSE_r)\n",
        "print(\"RMSE :\",RMSE_r)\n",
        "\n",
        "\n",
        "#calculate MAE\n",
        "MAE_r= mean_absolute_error(y_train, y_pred_train_ridge)\n",
        "print(\"MAE :\",MAE_r)\n",
        "\n",
        "\n",
        "#import the packages\n",
        "from sklearn.metrics import r2_score\n",
        "#calculate r2 and adjusted r2\n",
        "r2_r= r2_score(y_train, y_pred_train_ridge)\n",
        "print(\"R2 :\",r2_r)\n",
        "Adjusted_R2_r=(1-(1-r2_score(y_train, y_pred_train_ridge))*((X_test.shape[0]-1)/(X_test.shape[0]-X_test.shape[1]-1)) )\n",
        "print(\"Adjusted R2 :\",1-(1-r2_score(y_train, y_pred_train_ridge))*((X_test.shape[0]-1)/(X_test.shape[0]-X_test.shape[1]-1)) )"
      ],
      "metadata": {
        "id": "picdtDVrm2Iu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Looks like our r2 score value is 0.80 that means our model is  able to capture most of the data variance. Lets save it in a dataframe for later comparisons."
      ],
      "metadata": {
        "id": "dfwCEp-dm5dG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Plot the figure\n",
        "plt.figure(figsize=(15,10))\n",
        "plt.plot((y_pred_test_ridge))\n",
        "plt.plot((np.array(y_test)))\n",
        "plt.legend([\"Predicted\",\"Actual\"])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "hLcrZ8rqm3fG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Checking Heteroscadacity after Ridge regression."
      ],
      "metadata": {
        "id": "tCiaHG6DjZkn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### Heteroscadacity\n",
        "plt.scatter((y_pred_test_ridge),(y_test)-(y_pred_test_ridge))"
      ],
      "metadata": {
        "id": "3Nv4dnm8m--2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# storing the test set metrics value in a dataframe for later comparison\n",
        "dict1={'Model':'Ridge regression ',\n",
        "       'MAE':round((MAE_r),3),\n",
        "       'MSE':round((MSE_r),3),\n",
        "       'RMSE':round((RMSE_r),3),\n",
        "       'R2_score':round((r2_r),3),\n",
        "       'Adjusted R2':round((Adjusted_R2_r ),2)}\n",
        "training_df=training_df.append(dict1,ignore_index=True)"
      ],
      "metadata": {
        "id": "MsJp0PdhoqCe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# storing the test set metrics value in a dataframe for later comparison\n",
        "dict2={'Model':'Ridge regression ',\n",
        "       'MAE':round((MAE_r),3),\n",
        "       'MSE':round((MSE_r),3),\n",
        "       'RMSE':round((RMSE_r),3),\n",
        "       'R2_score':round((r2_r),3),\n",
        "       'Adjusted R2':round((Adjusted_R2_r ),2)}\n",
        "test_df=test_df.append(dict2,ignore_index=True)"
      ],
      "metadata": {
        "id": "3HoWs8NCorxq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**CONCLUSION**"
      ],
      "metadata": {
        "id": "bG5wXwdZnYlX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "While working on analysis for seol dataset, we initially did EDA on all the features of the datset. We first analysed our dependent variable, 'Rented Bike Count' and also transformed it. Next we analysed categorical variable and dropped the variable which has majority of one class, we also analysed numerical variables,found the correlation, distribution and their relationship with the dependent variable. We also removed some numerical features which has  most 0 values and hot encoded the categorical variables.\n",
        "\n",
        "Next we implemented few machine learning algorithms like Linear Regression,lasso and ridge regression. We checked Heteroscadacity to improve our model performance.Also we calculated evaluation matrix to check model accuracy.\n",
        " "
      ],
      "metadata": {
        "id": "j1LGuBa7naxX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# displaying the results of evaluation metric values for all models\n",
        "result=pd.concat([training_df,test_df],keys=['Training set','Test set'])\n",
        "result"
      ],
      "metadata": {
        "id": "ohNhDwAxnY63"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Results of evaluation are:**\n",
        "• No overfitting is seen.\n",
        "\n",
        "• Linear as well as ridge Regression is giving the best score of our model with 80% accuracy.\n",
        "\n",
        "• Outliers of numerical columns have been treated by trimming method but       outliers of categorical columns have been left as they are because we cant define classed outliers.\n",
        "\n",
        "• The outliers of Dependent variable are transformed because they can't be changed.\n",
        "\n",
        "• Our Evalaution matrix shows that there is minimum error in this model.\n",
        "\n",
        "• We can deploy this model."
      ],
      "metadata": {
        "id": "4cnAgClOo1xG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "However, this is not the ultimate end. As this data is time dependent, the values for variables like temperature, windspeed, solar radiation etc., will not always be consistent. Therefore, there will be scenarios where the model might not perform well. As Machine learning is an exponentially evolving field, we will have to be prepared for all contingencies and also keep checking our model from time to time. Therefore, having a quality knowledge and keeping pace with the ever evolving ML field would surely help one to stay a step ahead in future."
      ],
      "metadata": {
        "id": "XyOlMhsko5X5"
      }
    }
  ]
}